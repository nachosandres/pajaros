{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this IPython notebook, an interactive exploration of how birdsong audio can be preprocessed and segmented will be carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# required libraries that will be used\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sig\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the data contained in the audio, a module of the scipy library (*scipy.io.wavfile*) can directy be used for that. In this case, the *RN5664* recording (avaliable in the *data/raw_wav_files* directory of the prokect repository) will be used. This exploration could be easily carried out over a different recording by just changing the *wav_file_path* variable in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wav file to use in this interactive exploration\n",
    "wav_file_path = \"../data/LIFECLEF2014_BIRDAMAZON_XC_WAV_RN5664.wav\"\n",
    "# import data from wav\n",
    "raw_sample_rate, raw_wav_data = wavfile.read(wav_file_path)\n",
    "print \"Audio file info:\"\n",
    "print \" - sample_rate = {} Hz\".format(raw_sample_rate)\n",
    "print \" - number samples = {}\".format(len(raw_wav_data))\n",
    "print \" - duration = {:.2f} s\".format(len(raw_wav_data)/float(raw_sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample rate of the raw audio file is $44100~\\rm{Hz}$ and its duration is approximately 7 minutes and a half. First, we can lot directly the waveform and also add a audio player to listen to the audio sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "\n",
    "time_array = np.linspace(0,len(raw_wav_data)/float(raw_sample_rate),len(raw_wav_data))\n",
    "ax.plot(time_array, raw_wav_data)\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"Raw Audio Signal (44100 Hz)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Signal Amplitude\")\n",
    "\n",
    "Audio(data = raw_wav_data, rate=raw_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the field recording studied, noise from the a bird is present but a lot of background noise is also present (e.g. from the recording device or other animals). We can also compute the spectogram of the recording (that corresponds with the Short Time Fourier Transform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "NFFT=1024\n",
    "noverlap = 256\n",
    "window = np.kaiser(NFFT,8) \n",
    "spectogram, freqs, time_array, im = ax.specgram(raw_wav_data, NFFT, raw_sample_rate,\n",
    "                                                noverlap, window=window,\n",
    "                                                cmap = 'Greys')\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"Spectogram Raw Signal (44100 Hz)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_ylim(freqs.min(), freqs.max());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the spectogram, the bird sounds are easier to recognize from the background sound. In order to ease the segmentation process (reduce the amount of information to process) and because the loudest part of bird songs are not usually above $6000~\\rm{Hz}$ the audio signal is going to be downsampled by a factor of 4. This limit the maximum possibel frecuency (*Nyquist frecuency*) to $5512.5~\\rm{Hz}$. The downsampled wave form and audio are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import decimate\n",
    "\n",
    "downsample_factor = 4\n",
    "sample_rate = raw_sample_rate/4\n",
    "wav_data = decimate( raw_wav_data, downsample_factor )\n",
    "\n",
    "print \"Down-sampled Audio info:\"\n",
    "print \" - sample_rate = {} Hz\".format(sample_rate)\n",
    "print \" - number samples = {}\".format(len(raw_wav_data))\n",
    "print \" - duration = {:.2f} s\".format(len(raw_wav_data)/float(raw_sample_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "\n",
    "time_array = np.linspace(0,len(wav_data)/float(sample_rate),len(wav_data))\n",
    "ax.plot(time_array,wav_data)\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"Downsampled Audio Signal (11025 Hz)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Signal Amplitude\")\n",
    "\n",
    "Audio(data = wav_data, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "NFFT=1024\n",
    "noverlap = 256\n",
    "window = np.kaiser(NFFT,8) \n",
    "spectogram, freqs, time_array, im = ax.specgram(wav_data, NFFT, sample_rate, noverlap, \n",
    "                                                window=window, cmap = 'Greys')\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"Spectogram Down-sampled Signal (11025 Hz)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_ylim(freqs.min(), freqs.max());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "\n",
    "# nyquist frequency\n",
    "nyq_freq = sample_rate/2. \n",
    "\n",
    "# design of highpass filter\n",
    "crit_freq_hz = 1000.              # critical frequency (normalized)\n",
    "N = 10                            # order of the niquist filter\n",
    "crit_freq = crit_freq_hz/nyq_freq # critical frequency (normalized)\n",
    "rp = 1                            # passband ripple (dB)\n",
    "rs = 80                           # stopband min attenuation (dB)\n",
    "btype = 'highpass'\n",
    "ftype = 'ellip'\n",
    "b, a = sig.iirfilter(N, crit_freq, rp, rs, btype, ftype)\n",
    "\n",
    "# apply previous filter\n",
    "wav_data_hp = sig.lfilter(b, a, wav_data)\n",
    "\n",
    "time_array = np.linspace(0,len(wav_data)/float(sample_rate),len(wav_data))\n",
    "ax.plot(time_array,wav_data_hp)\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"After {} Hz high pass filter (11025 Hz)\".format(crit_freq_hz))\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Signal Amplitude\")\n",
    "\n",
    "Audio(data = wav_data_hp, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "NFFT=1024\n",
    "noverlap = 256\n",
    "window = np.kaiser(NFFT,8) \n",
    "spectogram, freqs, time_array, im = ax.specgram(wav_data_hp, NFFT, sample_rate, noverlap, \n",
    "                                                window=window, cmap = 'Greys')\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"After {} Hz high pass filter (11025 Hz)\".format(crit_freq_hz))\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_ylim(freqs.min(), freqs.max());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from filtering import find_fundamental_freq\n",
    "\n",
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "\n",
    "# nyquist frequency\n",
    "nyq_freq = sample_rate/2. \n",
    "\n",
    "# find fundamental freq \n",
    "f_0 = find_fundamental_freq(wav_data_hp, sample_rate)\n",
    "f_0_ratio = 0.6\n",
    "print \"fund_freq: {:.2f} Hz\".format(f_0)\n",
    "# design of f_0 adaptive highpass filter\n",
    "N = 10                             # order of the niquist filter\n",
    "crit_freq = f_0_ratio*f_0/nyq_freq # critical frequency (normalized)\n",
    "rp = 1                             # passband ripple (dB)\n",
    "rs = 80                            # stopband min attenuation (dB)\n",
    "btype = 'highpass'\n",
    "ftype = 'ellip'\n",
    "b, a = sig.iirfilter(N, crit_freq, rp, rs, btype, ftype)\n",
    "\n",
    "# apply previous filter\n",
    "wav_data_df = sig.lfilter(b, a, wav_data_hp)\n",
    "\n",
    "time_array = np.linspace(0,len(wav_data)/float(sample_rate),len(wav_data))\n",
    "ax.plot(time_array,wav_data_df)\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"After f_0 dynamic filter (11025 Hz)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Signal Amplitude\")\n",
    "\n",
    "Audio(data = wav_data_df, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "NFFT=1024\n",
    "noverlap = 256\n",
    "window = np.kaiser(NFFT,8) \n",
    "spectogram, freqs, time_array, im = ax.specgram(wav_data_df, NFFT, sample_rate, noverlap, \n",
    "                                                window=window, cmap = 'Greys')\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"After f_0 dynamic filter (11025 Hz)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_ylim(freqs.min(), freqs.max());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from filtering import filter_chain\n",
    "\n",
    "# apply both filters together\n",
    "crit_freq = 1000  # Hz\n",
    "f0_ratio = 0.6    # multiplied by fundamental freq\n",
    "wav_data_fil = filter_chain(wav_data, sample_rate,\n",
    "                            crit_freq, f0_ratio)\n",
    "\n",
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "NFFT=1024\n",
    "noverlap = 256\n",
    "window = np.kaiser(NFFT,8) \n",
    "spectogram, freqs, time_array, im = ax.specgram(wav_data_df, NFFT, sample_rate, noverlap, \n",
    "                                                window=window, cmap = 'Greys')\n",
    "ax.set_xlim(time_array.min(), time_array.max())\n",
    "ax.set_title(\"After both filters (11025 Hz)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_ylim(freqs.min(), freqs.max());\n",
    "\n",
    "Audio(data = wav_data_fil, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from recursive_segmentation import find_syllables\n",
    "\n",
    "db_diff = 17\n",
    "\n",
    "syllables = find_syllables(spectogram, time_array, db_diff)\n",
    "\n",
    "# add syllables to plot as green shadows\n",
    "hspans = []\n",
    "for syllable in syllables:\n",
    "    hspans.append(ax.axvspan(syllable[0], syllable[1],\n",
    "                             facecolor='g', alpha = 0.2))\n",
    "# display figure\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from recursive_segmentation import join_in_segments\n",
    "\n",
    "max_silence = 0.8 # seconds\n",
    "segments = join_in_segments(syllables, 0.8)\n",
    "\n",
    "# add segments to plot as red shadows\n",
    "hspans = []\n",
    "for segment in segments:\n",
    "    hspans.append(ax.axvspan(segment[0], segment[1], facecolor='r', alpha = 0.2))\n",
    "\n",
    "# display figure\n",
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
